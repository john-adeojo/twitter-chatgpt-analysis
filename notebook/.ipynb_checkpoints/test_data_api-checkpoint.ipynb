{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98dc332b-ec32-472b-9704-0721408ed2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json \n",
    "#import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7cd0c57-708e-43ab-b1e2-7c8d71839ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91234527-ea43-47ed-ba90-ed1e67fe6ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 tweets from 2022-11-30 to 2022-12-01\n",
      "Processed 20 tweets from 2022-12-01 to 2022-12-02\n",
      "Processed 0 tweets from 2022-12-02 to 2022-12-03\n",
      "Processed 0 tweets from 2022-12-03 to 2022-12-04\n",
      "Processed 20 tweets from 2022-12-04 to 2022-12-05\n",
      "Processed 20 tweets from 2022-12-05 to 2022-12-06\n",
      "Processed 21 tweets from 2022-12-06 to 2022-12-07\n",
      "Processed 0 tweets from 2022-12-07 to 2022-12-08\n",
      "Processed 0 tweets from 2022-12-08 to 2022-12-09\n",
      "Processed 0 tweets from 2022-12-09 to 2022-12-10\n",
      "Processed 0 tweets from 2022-12-10 to 2022-12-11\n",
      "Processed 20 tweets from 2022-12-11 to 2022-12-12\n",
      "Processed 20 tweets from 2022-12-12 to 2022-12-13\n",
      "Processed 20 tweets from 2022-12-13 to 2022-12-14\n",
      "Processed 20 tweets from 2022-12-14 to 2022-12-15\n",
      "Processed 0 tweets from 2022-12-15 to 2022-12-16\n",
      "Processed 20 tweets from 2022-12-16 to 2022-12-17\n",
      "Processed 21 tweets from 2022-12-17 to 2022-12-18\n",
      "Processed 0 tweets from 2022-12-18 to 2022-12-19\n",
      "Processed 20 tweets from 2022-12-19 to 2022-12-20\n",
      "Processed 21 tweets from 2022-12-20 to 2022-12-21\n",
      "Processed 0 tweets from 2022-12-21 to 2022-12-22\n",
      "Processed 0 tweets from 2022-12-22 to 2022-12-23\n",
      "Processed 0 tweets from 2022-12-23 to 2022-12-24\n",
      "Processed 0 tweets from 2022-12-24 to 2022-12-25\n",
      "Processed 0 tweets from 2022-12-25 to 2022-12-26\n",
      "Processed 0 tweets from 2022-12-26 to 2022-12-27\n",
      "Processed 22 tweets from 2022-12-27 to 2022-12-28\n",
      "Processed 21 tweets from 2022-12-28 to 2022-12-29\n",
      "Processed 0 tweets from 2022-12-29 to 2022-12-30\n",
      "Processed 0 tweets from 2022-12-30 to 2022-12-31\n",
      "Processed 21 tweets from 2022-12-31 to 2023-01-01\n",
      "Processed 21 tweets from 2023-01-01 to 2023-01-02\n",
      "Processed 0 tweets from 2023-01-02 to 2023-01-03\n",
      "Processed 20 tweets from 2023-01-03 to 2023-01-04\n",
      "Processed 20 tweets from 2023-01-04 to 2023-01-05\n",
      "Processed 20 tweets from 2023-01-05 to 2023-01-06\n",
      "Processed 21 tweets from 2023-01-06 to 2023-01-07\n",
      "Processed 0 tweets from 2023-01-07 to 2023-01-08\n",
      "Processed 0 tweets from 2023-01-08 to 2023-01-09\n",
      "Processed 20 tweets from 2023-01-09 to 2023-01-10\n",
      "Processed 0 tweets from 2023-01-10 to 2023-01-11\n",
      "Processed 20 tweets from 2023-01-11 to 2023-01-12\n",
      "Processed 20 tweets from 2023-01-12 to 2023-01-13\n",
      "Processed 0 tweets from 2023-01-13 to 2023-01-14\n",
      "Processed 20 tweets from 2023-01-14 to 2023-01-15\n",
      "Processed 21 tweets from 2023-01-15 to 2023-01-16\n",
      "Processed 20 tweets from 2023-01-16 to 2023-01-17\n",
      "Processed 0 tweets from 2023-01-17 to 2023-01-18\n",
      "Processed 20 tweets from 2023-01-18 to 2023-01-19\n",
      "Processed 20 tweets from 2023-01-19 to 2023-01-20\n",
      "Processed 21 tweets from 2023-01-20 to 2023-01-21\n",
      "Processed 21 tweets from 2023-01-21 to 2023-01-22\n",
      "Processed 23 tweets from 2023-01-22 to 2023-01-23\n",
      "Processed 21 tweets from 2023-01-23 to 2023-01-24\n",
      "Processed 0 tweets from 2023-01-24 to 2023-01-25\n",
      "Processed 24 tweets from 2023-01-25 to 2023-01-26\n",
      "Processed 0 tweets from 2023-01-26 to 2023-01-27\n",
      "Processed 21 tweets from 2023-01-27 to 2023-01-28\n",
      "Processed 20 tweets from 2023-01-28 to 2023-01-29\n",
      "Processed 0 tweets from 2023-01-29 to 2023-01-30\n",
      "Processed 0 tweets from 2023-01-30 to 2023-01-31\n",
      "Processed 0 tweets from 2023-01-31 to 2023-02-01\n",
      "Processed 21 tweets from 2023-02-01 to 2023-02-02\n",
      "Processed 20 tweets from 2023-02-02 to 2023-02-03\n",
      "Processed 21 tweets from 2023-02-03 to 2023-02-04\n",
      "Processed 0 tweets from 2023-02-04 to 2023-02-05\n",
      "Processed 0 tweets from 2023-02-05 to 2023-02-06\n",
      "Processed 0 tweets from 2023-02-06 to 2023-02-07\n",
      "Processed 20 tweets from 2023-02-07 to 2023-02-08\n",
      "Processed 0 tweets from 2023-02-08 to 2023-02-09\n",
      "Processed 21 tweets from 2023-02-09 to 2023-02-10\n",
      "Processed 22 tweets from 2023-02-10 to 2023-02-11\n",
      "Processed 20 tweets from 2023-02-11 to 2023-02-12\n",
      "Processed 0 tweets from 2023-02-12 to 2023-02-13\n",
      "Processed 0 tweets from 2023-02-13 to 2023-02-14\n",
      "Processed 0 tweets from 2023-02-14 to 2023-02-15\n",
      "Processed 0 tweets from 2023-02-15 to 2023-02-16\n",
      "Processed 22 tweets from 2023-02-16 to 2023-02-17\n",
      "Processed 21 tweets from 2023-02-17 to 2023-02-18\n",
      "Processed 0 tweets from 2023-02-18 to 2023-02-19\n",
      "Processed 0 tweets from 2023-02-19 to 2023-02-20\n",
      "Processed 0 tweets from 2023-02-20 to 2023-02-21\n",
      "Processed 21 tweets from 2023-02-21 to 2023-02-22\n",
      "Processed 0 tweets from 2023-02-22 to 2023-02-23\n",
      "Processed 0 tweets from 2023-02-23 to 2023-02-24\n",
      "Processed 20 tweets from 2023-02-24 to 2023-02-25\n",
      "Processed 0 tweets from 2023-02-25 to 2023-02-26\n",
      "Processed 0 tweets from 2023-02-26 to 2023-02-27\n",
      "Processed 20 tweets from 2023-02-27 to 2023-02-28\n",
      "Processed 20 tweets from 2023-02-28 to 2023-03-01\n",
      "Processed 0 tweets from 2023-03-01 to 2023-03-02\n",
      "Processed 0 tweets from 2023-03-02 to 2023-03-03\n",
      "Processed 21 tweets from 2023-03-03 to 2023-03-04\n",
      "Processed 0 tweets from 2023-03-04 to 2023-03-05\n",
      "Processed 21 tweets from 2023-03-05 to 2023-03-06\n",
      "Processed 0 tweets from 2023-03-06 to 2023-03-07\n",
      "Processed 0 tweets from 2023-03-07 to 2023-03-08\n",
      "Processed 21 tweets from 2023-03-08 to 2023-03-09\n",
      "Processed 0 tweets from 2023-03-09 to 2023-03-10\n",
      "Processed 21 tweets from 2023-03-10 to 2023-03-11\n",
      "Processed 0 tweets from 2023-03-11 to 2023-03-12\n",
      "Processed 20 tweets from 2023-03-12 to 2023-03-13\n",
      "Processed 22 tweets from 2023-03-13 to 2023-03-14\n",
      "Processed 20 tweets from 2023-03-14 to 2023-03-15\n",
      "Processed 0 tweets from 2023-03-15 to 2023-03-16\n",
      "Processed 21 tweets from 2023-03-16 to 2023-03-17\n",
      "Processed 20 tweets from 2023-03-17 to 2023-03-18\n",
      "Processed 0 tweets from 2023-03-18 to 2023-03-19\n",
      "Processed 0 tweets from 2023-03-19 to 2023-03-20\n",
      "Processed 21 tweets from 2023-03-20 to 2023-03-21\n",
      "Processed 20 tweets from 2023-03-21 to 2023-03-22\n",
      "Processed 0 tweets from 2023-03-22 to 2023-03-23\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "search = \"#chatgpt\"\n",
    "url = \"https://twitter154.p.rapidapi.com/search/search\"\n",
    "limit = 20\n",
    "language = \"en\"\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"\",\n",
    "    \"X-RapidAPI-Host\": \"twitter154.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# Define start and end dates for the loop\n",
    "start_date = datetime.datetime(2022, 11, 30)\n",
    "end_date = datetime.datetime(2023, 3, 23)\n",
    "all_results = []\n",
    "# Loop over each day interval between start and end dates\n",
    "current_date = start_date\n",
    "while current_date < end_date:\n",
    "    # Set the current start and end dates for the day interval\n",
    "    current_start = current_date.strftime(\"%Y-%m-%d\")\n",
    "    current_end = (current_date + datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Set the query parameters for the API call\n",
    "    querystring = {\"query\": search, \"section\": \"latest\", \"limit\": limit, \"start_date\": current_start, \"end_date\": current_end, \"language\": language}\n",
    "    \n",
    "    # Make the API call and process the response\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    if response.status_code == 200:\n",
    "        # Process the response here\n",
    "        # ...\n",
    "        print(f\"Processed {len(response.json()['results'])} tweets from {current_start} to {current_end}\")\n",
    "        all_results.append(response.json()['results'])\n",
    "    else:\n",
    "        print(f\"Error {response.status_code} for dates {current_start} to {current_end}\")\n",
    "    \n",
    "    # Increment the current date by one day interval\n",
    "    current_date += datetime.timedelta(days=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d9235cf-5f1e-415b-8d73-4e9609c55529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_ids = [tweet['tweet_id'] for sublist in all_results for tweet in sublist]\n",
    "responses = []\n",
    "\n",
    "for tweet_id in tweet_ids:\n",
    "    \n",
    "    querystring = {'tweet_id': tweet_id}\n",
    "    \n",
    "    url = \"https://twitter154.p.rapidapi.com/tweet/details\"\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"\",\n",
    "        \"X-RapidAPI-Host\": \"twitter154.p.rapidapi.com\"\n",
    "    }    \n",
    "        \n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "    responses.append(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07ba22b7-2b22-4c68-aca3-89478cab591c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets_details_df = pd.json_normalize(responses)\n",
    "tweets_details_df.to_csv(rf\"C:\\Users\\johna\\anaconda3\\envs\\twitter-analytics-env\\twitter-chatgpt-analysis\\data\\01_raw\\tweets_chatgpt{timestamp}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6589a1-2a9a-48f1-9cd8-7a6522a6b343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
